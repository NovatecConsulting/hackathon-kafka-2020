:toc:
:toc-title:
:toclevels: 3

:sectanchors:
:sectlinks:

:cp-version: 5.4.0

= Confluent Cloud Quick Start Tutorial

This tutorial gives a short introduction into Confluent Cloud and describes how you can create a Kafka cluster in Confluent cloud and use it from a Kubernetes cluster.

If you prefer to just use an existing Kafka cluster, you can use the prepared Confluent Cloud environment, which have been created with the link:provision/[provisioning scripts].

This quick start tutorial is similar to the official https://docs.confluent.io/{cp-version}/quickstart/cloud-quickstart/index.html[Confluent Cloud Quick Start]. However, this tutorial is more releated to our Kafka Hackathon.

In this tutorial we:

- Create a Confluent Cloud Kafka cluster
- Create an API key to access the Kafka cluster

What this tutorial does not cover:

- Confluent Cloud Schema Registry
- Connection of other Confluent Plattform components like, Schema Registry, Connect and KSQL to Confluent Cloud.

== Prerequisite

In order to go through this quick start, you need:

- <<Access to Confluent Cloud>>
- <<Access to Kubernetes Cluster>>

On Windows, it is recommended to use an appropriate Linux environment in order to have the `curl` and `sh` commands available such as the https://docs.microsoft.com/en-us/windows/wsl/about[Windows Subsystem for Linux].

=== Access to Confluent Cloud

It is required, that you have credentials for https://confluent.cloud/ in order to create a Kafka cluster. It is recommended to use the provided User Account to share your results with other participants. 

Alternatively you can create your own account at https://confluent.cloud/.

=== Access to Kubernetes Cluster

It is required, that you are authorized to access a Kubernetes cluster with the rights to create Deployments, ReplicaSets, Pods and Services. It is recommended to use the provided KubeConfig file for the preconfigured Kubernetes cluster.

== Confluent Cloud Setup

Confluent Cloud can be administrated via the https://confluent.cloud[Confluent Cloud Web UI] order the https://docs.confluent.io/{cp-version}/cloud/cli/install.html[Confluent Cloud CLI].

In this tutorial we will use the Confluent Cloud CLI. However, it makes sense to login to https://confluent.cloud[Confluent Cloud Web UI] and watch the effects caused by the CLI commands.

=== Confluent Cloud CLI Installation

To use the Confluent Cloud CLI, you can install it on your system, or use the `ueisele/ccloud-k8s-toolbox` Docker image.

==== Docker Image

The Docker image link:../../tools/ccloud-k8s-toolbox[ueisele/ccloud-k8s-toolbox] contains all tools which are required for this tutorial.
You can run a container and execute all commands of this tutorial inside it:

[source,bash]
----
docker run --rm -it -v ~/.ccloud:/root/.ccloud -v ~/.kube:/root/.kube -v ueisele/ccloud-k8s-toolbox:latest
----

==== Installation

The Confluent Cloud CLI is supported for macOS, Microsoft Windows, and Linux. If you would like to install it, just follow the instructions in the https://docs.confluent.io/{cp-version}/cloud/cli/install.html[Confluent Cloud CLI documentation].

Basically you just have tu execute the following command (~/.local/bin needs to be in your path).

[source,bash]
----
curl -L https://cnfl.io/ccloud-cli | sh -s -- -b ~/.local/bin
----

=== Create a Kafka cluster in Confluent Cloud

A Kafka cluster in Confluent Cloud is always assigned to exactly one environment. You can create multiple environments (e.g. prod,staging,dev) and within an enviornment multiple Kafka clusters can be created (e.g. platform, import).
In the Confluent Cloud documentation, the https://docs.confluent.io/current/cloud/limits.html[the limits and supported features] are described. On this page it is stated, that only 5 clusters are supported, however, it was possible to create more than 5 clusters. 

Before we can start with the creation of an environment and a cluster, you must login with the Confluent Cloud CLI.

.Run this command to log in to your Confluent Cloud account.
[source,bash]
----
ccloud login
----

==== Create Environment

First, you must create an environment. To avoid conflicts with others, prefix your environment with your team name

.Create environment
[source,bash]
----
ccloud environment create ueisele-hackathon-example
----

.Set environment in your context as the active environment
[source,bash]
----
>>> ccloud environment list 
     Id    |           Name             
+----------+---------------------------+
  * t24992 | default                    
    t25232 | ueisele-hackathon-example

>>> ccloud environment use t25232
Now using t25232 as the default (active) environment
----

==== Create Kafka cluster

Now, you can create a Kafka cluster within your new environment.
Confluent Cloud supports the creation of clusters on AWS, GCP and Azure. We will use GCP for this example, because it is the cheapest cloud.

It is possible to create single zone, as well as multi zone clusters. If you would like to create a multi zone cluster, you have to use the https://confluent.cloud[Confluent Cloud Web UI], because intil now only single zone clusters can be create via the Confluent Cloud CLI.
How to create a Kafka cluster with the Web UI is explained at the https://docs.confluent.io/current/quickstart/cloud-quickstart/index.html#step-1-create-a-kafka-cluster-in-ccloud[Confluent Cloud Quick Start].

.Create a new Kafka cluster
[source,bash]
----
>>> ccloud kafka cluster create hackathon-example-cluster --cloud gcp --region europe-west3
+-------------+------------------------------------------------------------+
| Id          | lkc-12vmz                                                  |
| Name        | hackathon-example-cluster                                  |
| Endpoint    | SASL_SSL://pkc-xxxxx.europe-west3.gcp.confluent.cloud:9092 |
| ApiEndpoint | https://pkac-xxxxx.europe-west3.gcp.confluent.cloud        |
+-------------+------------------------------------------------------------+
----

Note the listed attributes, especially the cluster id and the endpoint, which is the Kafka bootstrap server.

Besides `gcp` the values `aws` and `azure` are supported for `--cloud` parameter.

.Set created Kafka cluster in your context as the active cluster
----
ccloud kafka cluster use lkc-12vmz
----

=== Access a Kafka cluster in Confluent Cloud

With Confluent Cloud CLI you can manage your Kafka clusters, including topic and ACL management.

For mor details, see https://docs.confluent.io/{cp-version}/cloud/access-management/index.html[Manage Confluent Cloud Access].

==== Create an API Key

An API key and associated secret is required for producers and consumers on that new cluster.
You can generate the API key from the https://docs.confluent.io/{cp-versopm}/quickstart/cloud-quickstart/index.html#step-4-create-an-api-key[Confluent Cloud Web UI] or from the Confluent Cloud CLI. 

If an API key is created from the CLI, it is assigned to the active Kafka cluster. 

.Create an API key
[source,bash]
----
>>> ccloud api-key create --description "Demo credentials with full cluster access" --resource lkc-12vmz
Save the API key and secret. The secret is not retrievable later.
+---------+------------------------------------------------------------------+
| API Key | ABCDEFGHIJKLMNOP                                                 |
| Secret  | abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmnopqrstuvwxyz01 |
+---------+------------------------------------------------------------------+
----

Typically, you would not create one API key with full access for all your application. 
The recommended approach is o create a dedicated API key for each application and only enable access to required resources and operations.

Confluent Cloud CLI can also act as procuder and consumer on a cluster. In order to enable the CLI to do that, it is necessary to activate an appropriate API key. 

.Optional: If you created the API key via the UI, it must be stored.
[source,bash]
----
ccloud api-key store ABCDEFGHIJKLMNOP abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmnopqrstuvwxyz01 \
--resource lkc-12vmz
----

.Set the created API key as active key
[source,bash]
----
ccloud api-key use ABCDEFGHIJKLMNOP --resource lkc-12vmz
----

==== Test access to Kafka cluster

The created API key provides full access to the Kafka cluster. To test this, we can produce and consume records with the Confluent Cloud CLI.

.Create a topic (for this operation the CLI requires no API key)
[source,bash]
----
ccloud kafka topic create users
----

.Inspect the topic
[source,bash]
----
>>> ccloud kafka topic describe users
Topic: users PartitionCount: 6 ReplicationFactor: 3
  Topic | Partition | Leader | Replicas |   ISR    
+-------+-----------+--------+----------+---------+
  users |         0 |      2 | [2 8 0]  | [2 8 0]  
  users |         1 |      3 | [3 1 6]  | [3 1 6]  
  users |         2 |      4 | [4 2 3]  | [4 2 3]  
  users |         3 |      5 | [5 4 8]  | [5 4 8]  
  users |         4 |      6 | [6 7 1]  | [6 7 1]  
  users |         5 |      7 | [7 5 2]  | [7 5 2] 
----

If you describe the topic, you see, that it has been created with 6 partitions and a replication factor of 3.

.Produce records to users topic (this operations requires an API key)
[source,bash]
----
ccloud kafka topic produce users
----

.You can type messages in as standard input (Key and value is separated with ':')
[source,bash]
----
Starting Kafka Producer. ^C or ^D to exit
key:value
hello:world
^C
----

.Consume records from users topic (this operations requires an API key)
[source,bash]
----
ccloud kafka topic consume users --from-beginning
----

The records can also be viewed from the Confluent Cloud Web UI, see https://docs.confluent.io/{cp-version}/quickstart/cloud-quickstart/index.html#step-5-create-sample-producer[Confluent Cloud Quick Start]

==== Connect Confluent Platform components to Confluent Cloud

To connect Confluent Platform components to Confluent Cloud, see https://docs.confluent.io/{cp-version}/cloud/connect/index.html.
If you would like to configure and connect clients, see https://docs.confluent.io/current/cloud/using/config-client.html.